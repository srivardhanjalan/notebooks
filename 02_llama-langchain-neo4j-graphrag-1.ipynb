{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fff4d3f",
   "metadata": {},
   "source": [
    "#Background\n",
    "\n",
    "This is a experimentation setup to use LLaMA3 LLM, Langchain and Neo4j, to create a GraphRAG Setup and execute queries to draw insights.\n",
    "\n",
    "##Steps at a Glance\n",
    "\n",
    "1. Install Required Dependencies\n",
    "2. Create a Neo4j Account and Start a Aura DB Instance\n",
    "3. Setup Credentials and LLM\n",
    "4. Setup text to be used to create the Knowledge Graph\n",
    "5. Create the Knowledge Graph\n",
    "6. Connect to Neo4j AuraDB and add the Graph\n",
    "7. Visualize the Graph\n",
    "8. Execute a simple Query\n",
    "9. Create a Vector Index to perform Hybrid Search\n",
    "10. Test the Vector Index Embeddings\n",
    "11. Bringing it Together!\n",
    "12. References\n",
    "\n",
    "\n",
    "##Step 1.\n",
    "\n",
    "Install the required Neo4j and Langchanin dependencies. \n",
    "\n",
    "[Prerequisite] Please Install Ollama to execute the LLaMA LLM, and Setup Jupyter Notebooks locally by following Step 1 & 2 in the following Notebook - llama-langchain-experimentaion.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e4bf3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet neo4j yfiles_jupyter_graphs_for_neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "511e866b-fec2-40b4-b116-5790a6a023a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet  json-repair networkx langchain-core langchain-experimental langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae93a72a",
   "metadata": {},
   "source": [
    "##2. Create a Neo4j Account and Start an Aura DB Instance\n",
    "\n",
    "Go To: https://neo4j.com/product/auradb/ and Click on `Get Started for Free`\n",
    "Create an Account and Login. Alternatively use your Gmail creentials to Signup & Login.\n",
    "Create a Free AuraDB Instance and wait for it to start up. \n",
    "\n",
    "Please Note: Ensure to download/copy the credentials for the AuraDB Instance and store it safely.\n",
    "\n",
    "##3. Setup Credentials and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92094bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# url = \"YOUR NEO4J AURADB CONNECTION URL\"\n",
    "# username = \"neo4j\"\n",
    "# password = \"YOUR NEO4J AURADB PASSWORD\"\n",
    "\n",
    "url = \"neo4j+s://09fbbea4.databases.neo4j.io\"\n",
    "username = \"neo4j\"\n",
    "password = \"b1DuxkBtK_Kt2aPxOrwJcukeq5pmWq2FPsT9LJUGEr4\"\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1\", temperature=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d623b4",
   "metadata": {},
   "source": [
    "##4. Setup text to be used to create the Knowledge Graph\n",
    "\n",
    "If the `useStaticText` flag is turned off, it will pull information from a website and split the data into chunks for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90e8232e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "useStaticText = True\n",
    "docs = []\n",
    "\n",
    "if useStaticText:\n",
    "    text = \"\"\"\n",
    "    Marie Curie, born in 1867, was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity.\n",
    "    She was the first woman to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.\n",
    "    Her husband, Pierre Curie, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\n",
    "    She was, in 1906, the first woman to become a professor at the University of Paris. \n",
    "    \"\"\"\n",
    "    docs = [Document(page_content=text)]\n",
    "\n",
    "else:\n",
    "    loader = WebBaseLoader([\"https://huggingface.co/blog/llama3\"])\n",
    "    documents = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fc38e6",
   "metadata": {},
   "source": [
    "##5. Create the Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "069cd2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:[Node(id='radioactivity', type='Field of Study', properties={}), Node(id='Marie Curie', type='Person', properties={}), Node(id='University of Paris', type='Institution', properties={}), Node(id='1867', type='Year', properties={}), Node(id='Nobel Prize', type='Award', properties={}), Node(id='two scientific fields', type='Field of Study', properties={}), Node(id='Pierre Curie', type='Person', properties={}), Node(id=\"Marie Curie's first Nobel Prize\", type='Event', properties={}), Node(id='five Nobel Prizes', type='Award', properties={}), Node(id='physicist and chemist', type='Occupation', properties={})]\n",
      "Relationships:[Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='1867', type='Year', properties={}), type='BORN_IN', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='physicist and chemist', type='Occupation', properties={}), type='WORKS_AS', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='radioactivity', type='Field of Study', properties={}), type='CONDUCTED_RESEARCH_ON', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Nobel Prize', type='Award', properties={}), type='FIRST_TO_WIN', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Nobel Prize', type='Award', properties={}), type='WON_TWICE', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='two scientific fields', type='Field of Study', properties={}), type='FIRST_TO_WIN_IN_TWO_FIELDS', properties={}), Relationship(source=Node(id='Pierre Curie', type='Person', properties={}), target=Node(id=\"Marie Curie's first Nobel Prize\", type='Event', properties={}), type='CO-WINNER_OF', properties={}), Relationship(source=Node(id='Pierre Curie', type='Person', properties={}), target=Node(id='Marie Curie', type='Person', properties={}), type='MARRIED_TO', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='University of Paris', type='Institution', properties={}), type='FIRST_WOMAN_TO_BECOME_PROFESSOR', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='five Nobel Prizes', type='Award', properties={}), type='LAUNCHED_FAMILY_LEGACY', properties={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(docs)\n",
    "\n",
    "# Configurations can be added as below to control the Kind of Nodes and Relationships in the KNowledge Graph.\n",
    "#\n",
    "# llm_transformer_filtered = LLMGraphTransformer(\n",
    "#     llm=llm,\n",
    "#     allowed_nodes=[\"Person\", \"Country\", \"Organization\"],\n",
    "#     allowed_relationships=[\"NATIONALITY\", \"LOCATED_IN\", \"WORKED_AT\", \"SPOUSE\"],\n",
    "# )\n",
    "# graph_documents_filtered = llm_transformer_filtered.convert_to_graph_documents(\n",
    "#     d\n",
    "# )\n",
    "\n",
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e30835",
   "metadata": {},
   "source": [
    "##6. Connect to Neo4j AuraDB and add the Graph\n",
    "\n",
    "Please change the flag `addGraphDocuments` to `True` when creating the Knowledge Graph for the first time. It is set to `False` to prevent subsequent run for crearing duplicate nodes in the Knowledge Graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17eb1184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=url, \n",
    "    username=username, \n",
    "    password=password\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f31e94cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "addGraphDocuments = False\n",
    "\n",
    "if addGraphDocuments:\n",
    "    graph.add_graph_documents(\n",
    "        graph_documents,\n",
    "        baseEntityLabel=True, \n",
    "        include_source=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3624a0db",
   "metadata": {},
   "source": [
    "##7. Visualize the Graph\n",
    "\n",
    "Please Note: If you get an error with the YFiles Widget, please ensure you close the reopen the Jupyter Notebook to ensure the dependencies are loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4df3b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4287ac4547947a79ff277f794f85b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='610px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from yfiles_jupyter_graphs_for_neo4j import Neo4jGraphWidget\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "driver = GraphDatabase.driver(uri = url, auth = (username, password))\n",
    "g = Neo4jGraphWidget(driver)\n",
    "g.show_cypher(\"MATCH (s)-[r]->(t) RETURN s,r,t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d48bef",
   "metadata": {},
   "source": [
    "##8. Execute a simple Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6925994d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Person)-[:WORKS_AS]->(o:Occupation) RETURN o.id AS occupationId, p.id AS personId\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'occupationId': 'physicist and chemist', 'personId': 'Marie Curie'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'what do the people work as?',\n",
       " 'result': 'Physicist and chemist.',\n",
       " 'intermediate_steps': [{'query': 'MATCH (p:Person)-[:WORKS_AS]->(o:Occupation) RETURN o.id AS occupationId, p.id AS personId'},\n",
       "  {'context': [{'occupationId': 'physicist and chemist',\n",
       "     'personId': 'Marie Curie'}]}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import GraphCypherQAChain\n",
    "\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    graph=graph, \n",
    "    llm=llm, \n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True,\n",
    "    allow_dangerous_requests=True\n",
    ")\n",
    "\n",
    "response = chain.invoke({\"query\": \"what do the people work as?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac739896",
   "metadata": {},
   "source": [
    "##9. Create a Vector Index to perform Hybrid Search\n",
    "\n",
    "We use the Ollama Embeddings to create a Vecor Index for the the exising Graph we defined above. An `embedding` field is added to the Node with lable `Document` and it's `text` field is used to create the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58b3330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "\n",
    "\n",
    "ollama_emb = OllamaEmbeddings(\n",
    "    model=\"llama3.1\"\n",
    ")\n",
    "\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    ollama_emb,\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\",\n",
    "    url=url, username=username, password=password\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fa0a21",
   "metadata": {},
   "source": [
    "##10. Test the Vector Index Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "483fa7cf-71d1-41db-b516-8b48ea58b4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "text: \n",
      "    Marie Curie, born in 1867, was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity.\n",
      "    She was the first woman to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.\n",
      "    Her husband, Pierre Curie, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\n",
      "    She was, in 1906, the first woman to become a professor at the University of Paris. \n",
      "    \n",
      "1\n"
     ]
    }
   ],
   "source": [
    "query = \"what do the people work as?\"\n",
    "\n",
    "results = vector_index.similarity_search(query, k=10)\n",
    "print(results[0].page_content)\n",
    "\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02313d70",
   "metadata": {},
   "source": [
    "##11. Bringing it Together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37a60a0e-ebfb-4c42-b70a-3fdff4840b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srjalan/miniconda3/lib/python3.12/site-packages/langsmith/client.py:323: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "qa_chain = (\n",
    "    {\n",
    "        \"context\": vector_index.as_retriever(),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "qa_chain.invoke(\"Who are the people mentioned and what do thet work as?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9e401b",
   "metadata": {},
   "source": [
    "##12. References\n",
    "\n",
    "[Neo4j Vector Index](https://python.langchain.com/docs/integrations/vectorstores/neo4jvector/)\n",
    "[Migrating from RetrievalQA](https://python.langchain.com/docs/versions/migrating_chains/retrieval_qa/)\n",
    "[Enhancing the Accuracy of RAG Applications With Knowledge Graphs](https://neo4j.com/developer-blog/enhance-rag-knowledge-graph/)\n",
    "[The Neo4j GraphRAG Package for Python](https://neo4j.com/developer-blog/neo4j-graphrag-python-package/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
