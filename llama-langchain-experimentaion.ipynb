{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Background\n",
    "\n",
    "This is a experimentation setup to use llama LLM and Langchain, to execute contextual queries with personal data and derive insights.\n",
    "\n",
    "##Steps at a Glance\n",
    "\n",
    "1. Setup llama LLM Locally and Execute Test Queries\n",
    "2. Start Jupyter Notebooks locally\n",
    "3. Setup and Execute queries using Langchain\n",
    "4. Download Cricket Data\n",
    "5. Read the Cricket Data using Langchain\n",
    "6. Create Vector Indexes for the Data\n",
    "7. Setup Conversation Chat History \n",
    "8. Execute Queries\n",
    "\n",
    "###1. Setup llama LLM Locally and Execute Test Queries\n",
    "\n",
    "#####Use homebrew to install Ollama\n",
    "`brew install ollama`\n",
    "\n",
    "#####Using Ollama pull the llama3.1 8B LLM and run it\n",
    "`ollama pull llama3.1`\n",
    "`ollama run llama3.1`\n",
    "\n",
    "#####Execute Queries\n",
    "\n",
    "Queries can be executed using the Command Line, where llama has started up and using Curl as shown below\n",
    "\n",
    "```\n",
    "curl http://localhost:11434/api/chat -d '{\n",
    "  \"model\": \"llama3.1\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"who wrote the book godfather?\"\n",
    "    }\n",
    "  ],\n",
    "  \"stream\": false\n",
    "}'\n",
    "```\n",
    "\n",
    "###2. Start Jupyter Notebooks locally\n",
    "```\n",
    "conda install jupyter\n",
    "jupyter notebook --no-browser\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
